{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Aim: Analyze and demonstrate the working of HDFS architecture and commands and interpret MapReduce concepts and job outputs without program execution."
      ],
      "metadata": {
        "id": "pdIAIKgRiETU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuZJtfT5gVIR",
        "outputId": "f32b7f0c-0210-488c-ec0e-3efe60e16524"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tmp', 'user']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Simulated HDFS root\n",
        "hdfs_root = \"/content/hdfs\"\n",
        "\n",
        "# Create directory structure\n",
        "directories = [\n",
        "    \"user\",\n",
        "    \"user/data\",\n",
        "    \"user/data/input\",\n",
        "    \"user/data/output\",\n",
        "    \"tmp\"\n",
        "]\n",
        "\n",
        "for dir_path in directories:\n",
        "    os.makedirs(os.path.join(hdfs_root, dir_path), exist_ok=True)\n",
        "\n",
        "os.listdir(hdfs_root)\n",
        "\n",
        "#HDFS stores data in a hierarchical directory structure\n",
        "#We simulate /user/data/input and /user/data/output\n",
        "#This mirrors real HDFS paths like: hdfs dfs -mkdir /user/data/input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Apply Various HDFS Commands (Interpretation + Simulation)\n",
        "# Create a sample file\n",
        "input_file = \"/content/sample.txt\"\n",
        "\n",
        "with open(input_file, \"w\") as f:\n",
        "    f.write(\"hadoop mapreduce hdfs\")\n",
        "\n",
        "input_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jx6AqQ65hwFg",
        "outputId": "942b9fa6-5471-442b-bebe-970d6aeee2af"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sample.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(input_file, \"/content/hdfs/user/data/input/sample.txt\")\n",
        "\n",
        "#Equivalent HDFS Command: hdfs dfs -put sample.txt /user/data/input/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "e3RNdnN9il2A",
        "outputId": "97444f1f-6a42-4667-8fb5-6b3b2e296a2c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/hdfs/user/data/input/sample.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/hdfs/user/data/input\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkP6JWlwio4u",
        "outputId": "c0f243b0-3d79-49f8-eece-87ba41108db2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/hdfs/user/data/input/sample.txt\") as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN3Ix4KGi04R",
        "outputId": "e5a30e42-cf3d-456d-bdf0-5785e64b6490"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hadoop mapreduce hdfs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove(\"/content/hdfs/user/data/input/sample.txt\")"
      ],
      "metadata": {
        "id": "gyvZ7QtRi3FR"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Interpret MapReduce Program (Character Count)\n",
        "text = \"hadoop\""
      ],
      "metadata": {
        "id": "c16K-Zxhi_4g"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapper Phase\n",
        "mapped = []\n",
        "\n",
        "for char in text:\n",
        "    mapped.append((char, 1))\n",
        "\n",
        "mapped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm3fFclmkHm1",
        "outputId": "453ef1e0-87cd-4055-a813-4c00b54dbaf5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('h', 1), ('a', 1), ('d', 1), ('o', 1), ('o', 1), ('p', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle & Sort Phase\n",
        "from collections import defaultdict\n",
        "\n",
        "shuffled = defaultdict(list)\n",
        "\n",
        "for key, value in mapped:\n",
        "    shuffled[key].append(value)\n",
        "\n",
        "shuffled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqkg2glikKMD",
        "outputId": "af56a91d-9fff-4b30-e3c3-e9d84612779a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list, {'h': [1], 'a': [1], 'd': [1], 'o': [1, 1], 'p': [1]})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reducer Phase\n",
        "reduced = {}\n",
        "\n",
        "for key, values in shuffled.items():\n",
        "    reduced[key] = sum(values)\n",
        "\n",
        "reduced"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5GVXFKSkMRF",
        "outputId": "96365698-294b-4dd9-a807-9593978a1af3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'h': 1, 'a': 1, 'd': 1, 'o': 2, 'p': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in reduced.items():\n",
        "    print(f\"{k} : {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfJIvVylkPlV",
        "outputId": "a6cf391a-c18e-444c-811e-e4dbf52ba6ff"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h : 1\n",
            "a : 1\n",
            "d : 1\n",
            "o : 2\n",
            "p : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. View & Analyze MapReduce Job Logs (Interpretation)\n",
        "#Sample Job Log (Simulated)\n",
        "job_log = \"\"\"\n",
        "INFO JobClient: Running job: job_2026_0001\n",
        "INFO Mapper: Map tasks started\n",
        "INFO Mapper: Map output records = 6\n",
        "INFO Reducer: Reduce tasks started\n",
        "INFO Reducer: Reduce output records = 5\n",
        "INFO JobClient: Job completed successfully\n",
        "\"\"\"\n",
        "\n",
        "print(job_log)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHUOO8gUkRNy",
        "outputId": "51d7024f-3386-494f-a721-07fe1be8e474"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INFO JobClient: Running job: job_2026_0001\n",
            "INFO Mapper: Map tasks started\n",
            "INFO Mapper: Map output records = 6\n",
            "INFO Reducer: Reduce tasks started\n",
            "INFO Reducer: Reduce output records = 5\n",
            "INFO JobClient: Job completed successfully\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "otKQwvdukX1B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}